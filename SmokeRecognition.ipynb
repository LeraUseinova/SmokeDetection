{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LeraUseinova/SmokeDetection/blob/main/SmokeRecognition.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HwMLImazRR68"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/drive/MyDrive/Dataset/Datasets.zip -d /content/dataset"
      ],
      "metadata": {
        "id": "d05l8HDMRyRS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchmetrics"
      ],
      "metadata": {
        "id": "R5x_JELSi_KJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import torchvision\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import random\n",
        "import torch.nn as nn\n",
        "import torchvision.models as models\n",
        "from collections import OrderedDict\n",
        "from torchvision.models.resnet import BasicBlock\n",
        "from torchvision.models.resnet import Bottleneck\n",
        "import torchmetrics\n",
        "from sklearn.metrics import f1_score \n",
        "from sklearn.metrics import confusion_matrix"
      ],
      "metadata": {
        "id": "GXrnQ0oRR1-J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Гиперпараметры\n",
        "num_epochs = 100\n",
        "num_classes = 6\n",
        "batch_size = 32\n",
        "learning_rate = 0.001\n",
        "weight_decay = 0.0001\n",
        "\n",
        "# Конфигурация устройства\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Пути к папкам с данными\n",
        "train_dir = \"/content/dataset/Датасет/train\"\n",
        "val_dir = \"/content/dataset/Датасет/validation\"\n",
        "test_dir = \"/content/dataset/Датасет/test\""
      ],
      "metadata": {
        "id": "WAVGW9NAR14h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SQ2SKAoXlpml"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Вычисление среднего и стандартного отклонения по тренировочному датасету \n",
        "\"\"\" \n",
        "\n",
        "\n",
        "dataset = datasets.ImageFolder(train_dir, transform=transforms.ToTensor())\n",
        "loader = DataLoader(dataset, batch_size=batch_size,num_workers=2)\n",
        "\n",
        "def mean_std(loader):\n",
        "    \n",
        "    cnt = 0\n",
        "    fst_moment = torch.empty(3, dtype=torch.float32)\n",
        "    snd_moment = torch.empty(3, dtype=torch.float32)\n",
        "\n",
        "    with torch.no_grad():\n",
        "      for images, _ in loader:\n",
        "        b, c, h, w = images.shape\n",
        "        nb_pixels = b * h * w\n",
        "        sum_ = torch.sum(images, dim=[0, 2, 3], dtype=torch.float32)\n",
        "        sum_of_square = torch.sum(images ** 2, dim=[0, 2, 3], dtype=torch.float32)\n",
        "        fst_moment = (cnt * fst_moment + sum_) / (cnt + nb_pixels)\n",
        "        snd_moment = (cnt * snd_moment + sum_of_square) / (cnt + nb_pixels)\n",
        "        cnt += nb_pixels\n",
        "\n",
        "    mean, std = fst_moment, torch.sqrt(snd_moment - fst_moment ** 2)       \n",
        "    return mean,std\n",
        "\n",
        "mean, std = mean_std(loader)\n",
        "print(\"mean and std: \\n\",mean, std)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VbWHLiAClpmq"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        " Преобразование изображений\n",
        "\"\"\"\n",
        "\n",
        "data_transform = transforms.Compose([\n",
        "    transforms.RandomResizedCrop(224),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomVerticalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=mean, std=std)\n",
        "])\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=mean, std=std)\n",
        "])\n",
        "\n",
        "# Загрузка датасетов\n",
        "train_dataset = datasets.ImageFolder(train_dir, transform=data_transform)\n",
        "val_dataset = datasets.ImageFolder(val_dir, transform=transform)\n",
        "test_dataset = datasets.ImageFolder(test_dir, transform=transform)\n",
        "\n",
        "# Определяем загрузчики данных\n",
        "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "val_dataloader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size)\n",
        "test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size)\n",
        "\n",
        "classes = train_dataset.classes\n",
        "\n",
        "print('Classes: ',  classes)\n",
        "print('The train dataset have: ',  len(train_dataset) ,\" images.\")\n",
        "print('Number of train downloaded images per batch: ',  len(train_dataloader))\n",
        "print('The valid dataset have: ',  len(val_dataset),\" images.\")\n",
        "print('Number of valid downloaded images per batch: ',  len(val_dataloader))\n",
        "print('The test dataset have: ', len(test_dataset) ,\" images.\")\n",
        "print('Number of test downloaded images per batch: ',  len(test_dataloader))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qNOeY5Jwlpms"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Вычисление среднего и стандартного отклонения после преобразования\n",
        "\"\"\"\n",
        "\n",
        "mean_normal, std_normal = mean_std(train_dataloader)\n",
        "print(\"mean and std after normalize:\\n\",\n",
        "      mean_normal, std_normal)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b6jyBS5Ilpmu"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Вывод изображений до и после преобразования\n",
        "\"\"\"\n",
        "\n",
        "original_dataset = ImageFolder(train_dir)\n",
        "\n",
        "# Вывод по одной случайной картинке из каждого класса, после преобразований\n",
        "fig, axes = plt.subplots(nrows=len(original_dataset.class_to_idx), ncols=2, figsize=(10, 4 * len(original_dataset.class_to_idx)))\n",
        "\n",
        "for i, (class_name, class_idx) in enumerate(original_dataset.class_to_idx.items()):\n",
        "    # Извлечение всех изображений данного класса\n",
        "    images = original_dataset.imgs\n",
        "    class_images = [img[0] for img in images if img[1] == class_idx]\n",
        "\n",
        "    # Выбор случайного изображения из данного класса\n",
        "    torch.manual_seed(123)\n",
        "    random_image_path = random.sample(class_images, 1)[0]\n",
        "    image = Image.open(random_image_path)\n",
        "\n",
        "    # Применение преобразований к изображению\n",
        "    transformed_image = data_transform(image)\n",
        "\n",
        "    # Вывод изображений до и после преобразований\n",
        "    axes[i][0].imshow(image)\n",
        "    axes[i][0].set_title(f'{class_name} (original)')\n",
        "    axes[i][0].axis(\"off\")\n",
        "    axes[i][1].imshow(transformed_image.permute(1, 2, 0))\n",
        "    axes[i][1].set_title(f'{class_name} (transformed)')\n",
        "    axes[i][1].axis(\"off\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Добавляем к предобученной модели дропаут и механизмы внимания\n",
        "\"\"\"\n",
        "\n",
        "class SpatialAttention(nn.Module):\n",
        "    def __init__(self, in_channels):\n",
        "        super(SpatialAttention, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels, in_channels // 8, kernel_size=1)\n",
        "        self.conv2 = nn.Conv2d(in_channels // 8, 1, kernel_size=1)\n",
        "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
        "        self.max_pool = nn.AdaptiveMaxPool2d(1)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        avg_out = self.avg_pool(x)\n",
        "        avg_out = self.conv1(avg_out)\n",
        "        avg_out = self.conv2(avg_out)\n",
        "        max_out = self.max_pool(x)\n",
        "        max_out = self.conv1(max_out)\n",
        "        max_out = self.conv2(max_out)\n",
        "        out = torch.cat([avg_out, max_out], dim=1)\n",
        "        mask = self.sigmoid(out)\n",
        "        return x * mask\n",
        "\n",
        "class ChannelAttention(nn.Module):\n",
        "    def __init__(self, in_planes, ratio=16):\n",
        "        super(ChannelAttention, self).__init__()\n",
        "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
        "        self.max_pool = nn.AdaptiveMaxPool2d(1)\n",
        "        self.fc1 = nn.Conv2d(in_planes, in_planes // ratio, 1, bias=False)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.fc2 = nn.Conv2d(in_planes // ratio, in_planes, 1, bias=False)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        avg_pool = self.avg_pool(x)\n",
        "        max_pool = self.max_pool(x)\n",
        "        avg_out = self.fc2(self.relu(self.fc1(avg_pool)))\n",
        "        max_out = self.fc2(self.relu(self.fc1(max_pool)))\n",
        "        x = avg_out + max_out\n",
        "        x = self.sigmoid(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class ResNetWithAttention(nn.Module):\n",
        "    def __init__(self, num_classes=6):\n",
        "        super(ResNetWithAttention, self).__init__()\n",
        "        self.resnet = models.resnet18(pretrained=True)\n",
        "        \n",
        "        # Add channel attention and spatial attention modules to each residual block\n",
        "        for module in self.resnet.modules():\n",
        "            if isinstance(module, nn.Sequential):\n",
        "                for i in range(len(module)):\n",
        "                    if isinstance(module[i], BasicBlock):\n",
        "                        module[i].ca = ChannelAttention(module[i].conv2.out_channels)\n",
        "                        module[i].sa = SpatialAttention(module[i].conv2.in_channels)\n",
        "                    elif isinstance(module[i], Bottleneck):\n",
        "                        module[i].ca = ChannelAttention(module[i].conv3.out_channels)\n",
        "                        module[i].sa = SpatialAttention(module[i].conv3.in_channels)\n",
        "\n",
        "        # Replace the final fully connected layer to output 6 classes\n",
        "        num_features = self.resnet.fc.in_features\n",
        "        self.resnet.fc = nn.Sequential(\n",
        "            nn.Dropout(p=0.2),\n",
        "            nn.Linear(num_features, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.resnet.conv1(x)\n",
        "        x = self.resnet.bn1(x)\n",
        "        x = self.resnet.relu(x)\n",
        "        x = self.resnet.maxpool(x)\n",
        "\n",
        "        x = self.resnet.layer1(x)\n",
        "        x = self.resnet.layer2(x)\n",
        "        x = self.resnet.layer3(x)\n",
        "        x = self.resnet.layer4(x)\n",
        "\n",
        "        x = self.resnet.avgpool(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "\n",
        "        x = self.resnet.fc(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "model = ResNetWithAttention()\n",
        "            \n",
        "# Перемещение модели на GPU\n",
        "model.to(device)"
      ],
      "metadata": {
        "id": "ubLAD5Yk1KFd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Обучаем модель\n",
        "\"\"\"\n",
        "class EarlyStopping:\n",
        "    def __init__(self, patience=10, delta=0, path='checkpoint.pt'):\n",
        "        self.patience = patience\n",
        "        self.delta = delta\n",
        "        self.path = path\n",
        "        self.counter = 0\n",
        "        self.best_score = None\n",
        "        self.early_stop = False\n",
        "        self.val_loss_min = np.Inf\n",
        "\n",
        "    def __call__(self, val_loss, model):\n",
        "        score = -val_loss\n",
        "\n",
        "        if self.best_score is None:\n",
        "            self.best_score = score\n",
        "            self.save_checkpoint(val_loss, model)\n",
        "        elif score < self.best_score + self.delta:\n",
        "            self.counter += 1\n",
        "            if self.counter >= self.patience:\n",
        "                self.early_stop = True\n",
        "        else:\n",
        "            self.best_score = score\n",
        "            self.save_checkpoint(val_loss, model)\n",
        "            self.counter = 0\n",
        "\n",
        "    def save_checkpoint(self, val_loss, model):\n",
        "        torch.save(model.state_dict(), self.path)\n",
        "        self.val_loss_min = val_loss\n",
        "\n",
        "early_stopping = EarlyStopping(patience=10)\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5)\n",
        "\n",
        "# Код для обучения модели\n",
        "train_loss = []\n",
        "train_acc = []\n",
        "val_loss = []\n",
        "val_acc = []\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    # Обучение модели на тренировочном датасете\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for images, labels in train_dataloader:\n",
        "        # Перемещаем тензоры на устройство\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # Прямое прохождение \n",
        "        outputs = model(images)\n",
        "        loss = loss_fn(outputs, labels)\n",
        "\n",
        "        # Добавление регуляризации\n",
        "        for name, param in model.named_parameters():\n",
        "            if 'weight' in name:\n",
        "                l2_regularization = torch.norm(param)\n",
        "                loss += weight_decay * l2_regularization\n",
        "\n",
        "        # Обратное прхождение и оптимизация              \n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item() * images.size(0)\n",
        "        _, preds = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (preds == labels).sum().item()\n",
        "\n",
        "        # Очищаем память на устройстве\n",
        "        del images, labels, outputs\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "    epoch_train_loss = running_loss / len(train_dataloader.dataset)\n",
        "    epoch_train_acc = 100 * correct / total\n",
        "    train_loss.append(epoch_train_loss)\n",
        "    train_acc.append(epoch_train_acc)\n",
        "\n",
        "    # Проверка модели на валидационном датасете\n",
        "    model.eval()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for images, labels in val_dataloader:\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            outputs = model(images)\n",
        "            loss = loss_fn(outputs, labels)\n",
        "\n",
        "            running_loss += loss.item() * images.size(0)\n",
        "            _, preds = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (preds == labels).sum().item()\n",
        "\n",
        "            # Очищаем память на устройстве\n",
        "            del images, labels, outputs\n",
        "            torch.cuda.empty_cache()\n",
        "\n",
        "    epoch_val_loss = running_loss / len(val_dataloader.dataset)\n",
        "    epoch_val_acc = 100 * correct / total\n",
        "    val_loss.append(epoch_val_loss)\n",
        "    val_acc.append(epoch_val_acc)\n",
        "\n",
        "    print('Epoch [{}/{}], Train Loss: {:.4f}, Train Acc: {:.2f}%, Val Loss: {:.4f}, Val Acc: {:.2f}%'.format(epoch+1, num_epochs, epoch_train_loss, epoch_train_acc, epoch_val_loss, epoch_val_acc))\n",
        "    \n",
        "    # Сохраняем модель с лучшей точностью\n",
        "    best_acc = 0\n",
        "    if epoch_val_acc > best_acc:\n",
        "        best_acc = epoch_val_acc\n",
        "        torch.save({\n",
        "            'model': model,\n",
        "            'state_dict': model.state_dict()\n",
        "            }, '/content/resnet50_model_with_dropout_2.pth')\n",
        "\n",
        "    # Уменьшаем learning rate, если в течение 5 эпох точность не улучшается\n",
        "    scheduler.step(epoch_val_loss)\n",
        "    \n",
        "    # Останавливаем обучение, если в течение 10 эпох точность не улучшается\n",
        "    if early_stopping.early_stop:\n",
        "        print(\"Early stopping\")\n",
        "        break\n",
        "\n",
        "# Построение графиков\n",
        "fig, ax = plt.subplots(1, 2, figsize=(12, 5))\n",
        "\n",
        "ax[0].plot(train_loss, label='train')\n",
        "ax[0].plot(val_loss, label='validation')\n",
        "ax[0].set_title('Loss')\n",
        "ax[0].legend()\n",
        "\n",
        "ax[1].plot(train_acc, label='train')\n",
        "ax[1].plot(val_acc, label='validation')\n",
        "ax[1].set_title('Accuracy')\n",
        "ax[1].legend()"
      ],
      "metadata": {
        "id": "vB3da031lpm6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Тестируем модель\n",
        "\"\"\"\n",
        "# Загружаем модель\n",
        "checkpoint = torch.load('/content/resnet50.pth')\n",
        "model = checkpoint['model']\n",
        "model.load_state_dict(checkpoint['state_dict'])\n",
        "\n",
        "# Загрузка предобученной модели \n",
        "#model = models.resnet18(pretrained=True)\n",
        "\n",
        "# Замена последнего слоя (fc) на новый слой с 6 выходными нейронами\n",
        "#num_ftrs = model.fc.in_features\n",
        "#model.fc = torch.nn.Linear(num_ftrs, 6)\n",
        "\n",
        "# Загрузка сохраненных весов\n",
        "#model.load_state_dict(torch.load('/content/resnet18_model_with_attention_after_downsample.pth'))\n",
        "\n",
        "# Перемещение модели на устройство\n",
        "model = model.to(device)\n",
        "\n",
        "model.eval()\n",
        "y_true = []\n",
        "y_pred = []\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_dataloader:\n",
        "        # Перемещаем тензоры на устройство\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # Получаем прогнозы модели \n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "        # Вычисляем колличество правильных предсказаний\n",
        "        y_true.extend(labels.cpu().numpy())\n",
        "        y_pred.extend(predicted.cpu().numpy())\n",
        "\n",
        "accuracy = torchmetrics.functional.accuracy(torch.tensor(y_pred), torch.tensor(y_true), num_classes=num_classes, task='multiclass')\n",
        "precision = torchmetrics.functional.precision(torch.tensor(y_pred), torch.tensor(y_true), num_classes=num_classes, average='macro', task='multiclass')\n",
        "recall = torchmetrics.functional.recall(torch.tensor(y_pred), torch.tensor(y_true), num_classes=num_classes, average='macro', task='multiclass')\n",
        "f1 = f1_score(y_true, y_pred, average='macro')\n",
        "\n",
        "print('Accuracy: {:.4f}%, Precision: {:.4f}, Recall: {:.4f}, F1 score: {:.4f}'.format(accuracy * 100, precision, recall, f1))\n",
        "\n",
        "# Строим матрицу ошибок\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "print(\"confusion matrix: \\n\", cm)\n"
      ],
      "metadata": {
        "id": "Vc9A3LtDlpnA"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPw0h9ma+UmZPziLF1G0qAd",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}