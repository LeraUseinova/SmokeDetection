{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LeraUseinova/SmokeDetection/blob/main/SmokeDetection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HwMLImazRR68"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/drive/MyDrive/Dataset/Datasets.zip -d /content/dataset"
      ],
      "metadata": {
        "id": "d05l8HDMRyRS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchmetrics"
      ],
      "metadata": {
        "id": "R5x_JELSi_KJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import torchvision\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import random\n",
        "import torch.nn as nn\n",
        "import torchvision.models as models\n",
        "from collections import OrderedDict\n",
        "from torchvision.models.resnet import BasicBlock\n",
        "from torchvision.models.resnet import Bottleneck\n",
        "import torchmetrics\n",
        "from sklearn.metrics import f1_score \n",
        "from sklearn.metrics import confusion_matrix"
      ],
      "metadata": {
        "id": "GXrnQ0oRR1-J"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Гиперпараметры\n",
        "num_epochs = 100\n",
        "num_classes = 6\n",
        "batch_size = 32\n",
        "learning_rate = 0.001\n",
        "weight_decay = 0.0001\n",
        "\n",
        "# Конфигурация устройства\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Пути к папкам с данными\n",
        "train_dir = \"/content/dataset/Датасет/train\"\n",
        "val_dir = \"/content/dataset/Датасет/validation\"\n",
        "test_dir = \"/content/dataset/Датасет/test\""
      ],
      "metadata": {
        "id": "WAVGW9NAR14h"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SQ2SKAoXlpml"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Вычисление среднего и стандартного отклонения по тренировочному датасету \n",
        "\"\"\" \n",
        "\n",
        "\n",
        "dataset = datasets.ImageFolder(train_dir, transform=transforms.ToTensor())\n",
        "loader = DataLoader(dataset, batch_size=batch_size,num_workers=2)\n",
        "\n",
        "def mean_std(loader):\n",
        "    \n",
        "    # cnt — общее количество пикселей во всем наборе данных, fst_moment и snd_moment — первый и второй моменты набора данных соответственно\n",
        "    cnt = 0\n",
        "    fst_moment = torch.empty(3, dtype=torch.float32)\n",
        "    snd_moment = torch.empty(3, dtype=torch.float32)\n",
        "\n",
        "    # no_grad отключает вычисление градиента и сокращает использование памяти\n",
        "    with torch.no_grad():\n",
        "      # Перебираем изображения, игнорируя метки\n",
        "      for images, _ in loader:\n",
        "        # Вычисляем количество пикселей в тензоре images\n",
        "        b, c, h, w = images.shape\n",
        "        nb_pixels = b * h * w \n",
        "        # Сумма значений каждого пикселя по ширине и высоте изображения\n",
        "        sum_ = torch.sum(images, dim=[0, 2, 3], dtype=torch.float32) \n",
        "        # Сумма квадратов значений каждого пиксела по ширине и высоте изображения\n",
        "        sum_of_square = torch.sum(images ** 2, dim=[0, 2, 3], dtype=torch.float32)\n",
        "        # Обновляем значения первого и второго момента, и количество пикселей для текущего набора\n",
        "        fst_moment = (cnt * fst_moment + sum_) / (cnt + nb_pixels)\n",
        "        snd_moment = (cnt * snd_moment + sum_of_square) / (cnt + nb_pixels)\n",
        "        cnt += nb_pixels\n",
        "    # Вычисляем среднее значение и стандартное отклонение\n",
        "    mean, std = fst_moment, torch.sqrt(snd_moment - fst_moment ** 2)       \n",
        "    return mean,std\n",
        "\n",
        "mean, std = mean_std(loader)\n",
        "print(\"mean and std: \\n\",mean, std)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VbWHLiAClpmq"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        " Преобразование изображений\n",
        "\"\"\"\n",
        "# Набор преобразований данных, который включает случайные преобразования для увеличения разнообразия данных\n",
        "data_transform = transforms.Compose([\n",
        "    transforms.RandomResizedCrop(224),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomVerticalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=mean, std=std)\n",
        "])\n",
        "# Набор преобразований данных, который используется для тестирования и валидации и не включает случайных преобразований, \n",
        "# чтобы сохранить исходное изображение\n",
        "transform = transforms.Compose([\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=mean, std=std)\n",
        "])\n",
        "\n",
        "# Загрузка датасетов\n",
        "train_dataset = datasets.ImageFolder(train_dir, transform=data_transform)\n",
        "val_dataset = datasets.ImageFolder(val_dir, transform=transform)\n",
        "test_dataset = datasets.ImageFolder(test_dir, transform=transform)\n",
        "\n",
        "# Определяем загрузчики данных\n",
        "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "val_dataloader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size)\n",
        "test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size)\n",
        "\n",
        "classes = train_dataset.classes\n",
        "\n",
        "print('Classes: ',  classes)\n",
        "print('The train dataset have: ',  len(train_dataset) ,\" images.\")\n",
        "print('Number of train downloaded images per batch: ',  len(train_dataloader))\n",
        "print('The valid dataset have: ',  len(val_dataset),\" images.\")\n",
        "print('Number of valid downloaded images per batch: ',  len(val_dataloader))\n",
        "print('The test dataset have: ', len(test_dataset) ,\" images.\")\n",
        "print('Number of test downloaded images per batch: ',  len(test_dataloader))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qNOeY5Jwlpms"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Вычисление среднего и стандартного отклонения после преобразования\n",
        "\"\"\"\n",
        "\n",
        "mean_normal, std_normal = mean_std(train_dataloader)\n",
        "print(\"mean and std after normalize:\\n\",\n",
        "      mean_normal, std_normal)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b6jyBS5Ilpmu"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Вывод изображений до и после преобразования\n",
        "\"\"\"\n",
        "\n",
        "original_dataset = ImageFolder(train_dir)\n",
        "\n",
        "# Вывод по одной случайной картинке из каждого класса, после преобразований\n",
        "fig, axes = plt.subplots(nrows=len(original_dataset.class_to_idx), ncols=2, figsize=(10, 4 * len(original_dataset.class_to_idx)))\n",
        "\n",
        "for i, (class_name, class_idx) in enumerate(original_dataset.class_to_idx.items()):\n",
        "    # Извлечение всех изображений данного класса\n",
        "    images = original_dataset.imgs\n",
        "    class_images = [img[0] for img in images if img[1] == class_idx]\n",
        "\n",
        "    # Выбор случайного изображения из данного класса\n",
        "    torch.manual_seed(123)\n",
        "    random_image_path = random.sample(class_images, 1)[0]\n",
        "    image = Image.open(random_image_path)\n",
        "\n",
        "    # Применение преобразований к изображению\n",
        "    transformed_image = data_transform(image)\n",
        "\n",
        "    # Вывод изображений до и после преобразований\n",
        "    axes[i][0].imshow(image)\n",
        "    axes[i][0].set_title(f'{class_name} (original)')\n",
        "    axes[i][0].axis(\"off\")\n",
        "    axes[i][1].imshow(transformed_image.permute(1, 2, 0))\n",
        "    axes[i][1].set_title(f'{class_name} (transformed)')\n",
        "    axes[i][1].axis(\"off\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Добавляем к предобученной модели дропаут и механизмы внимания\n",
        "\"\"\"\n",
        "# Определение класса, реализующего пространственное внимание\n",
        "class SpatialAttention(nn.Module):\n",
        "    def __init__(self, in_channels):\n",
        "        super(SpatialAttention, self).__init__()\n",
        "        # Conv2d слой с ядром 1x1, который сокращает количество каналов на входе в 8 раз\n",
        "        self.conv1 = nn.Conv2d(in_channels, in_channels // 8, kernel_size=1) \n",
        "        # Conv2d слой с ядром 1x1, который преобразует выходной тензор conv1 в маску пространственного внимания\n",
        "        self.conv2 = nn.Conv2d(in_channels // 8, 1, kernel_size=1)\n",
        "        # Адаптивный слой пулинга среднего значения, который вычисляет среднее по каждому каналу \n",
        "        self.avg_pool = nn.AdaptiveAvgPool2d(1) \n",
        "        # Адаптивный слой максимального пулинга, который вычисляет максимальное значение по каждому каналу\n",
        "        self.max_pool = nn.AdaptiveMaxPool2d(1) \n",
        "        # Сигмоидный слой, который вычисляет маску пространственного внимания\n",
        "        self.sigmoid = nn.Sigmoid() \n",
        "\n",
        "    def forward(self, x):\n",
        "        # Применение адаптивного слоя среднего значения для вычисления среднего по каждому каналу\n",
        "        avg_out = self.avg_pool(x) \n",
        "        # Проход данных через первый слой свертки с ядром 1x1\n",
        "        avg_out = self.conv1(avg_out)\n",
        "        # Проход данных через второй слой свертки с ядром 1x1, чтобы получить маску внимания, отображающую важность каждой области изображения\n",
        "        avg_out = self.conv2(avg_out) \n",
        "        # Применение адаптивного слоя максимального значения для вычисления максимального значения по каждому каналу\n",
        "        max_out = self.max_pool(x) \n",
        "        # Проход данных через первый слой свертки, аналогичный avg_out, но использующий max_out в качестве входа\n",
        "        max_out = self.conv1(max_out) \n",
        "        # Проход данных через второй слой свертки для получения маски внимания, используя max_out\n",
        "        max_out = self.conv2(max_out) \n",
        "        # Объединение двух масок внимания вместе с использованием операции поэлементной конкатенации по оси каналов\n",
        "        out = torch.cat([avg_out, max_out], dim=1) \n",
        "        # Вычисление маски внимания, используя сигмоидную функцию для преобразования значений маски в промежутке от 0 до 1\n",
        "        mask = self.sigmoid(out)\n",
        "        return x * mask\n",
        "\n",
        "# Определение класса, реализующего канальное внимание\n",
        "class ChannelAttention(nn.Module):\n",
        "    def __init__(self, in_planes, ratio=16):\n",
        "        super(ChannelAttention, self).__init__()\n",
        "        # Адаптивный слой пуллинга среднего значения, который вычисляет среднее по каждому каналу\n",
        "        self.avg_pool = nn.AdaptiveAvgPool2d(1) \n",
        "        # Адаптивный слой максимального пулинга, который вычисляет максимальное значение по каждому каналу\n",
        "        self.max_pool = nn.AdaptiveMaxPool2d(1) \n",
        "        # Conv2d слой с ядром 1x1, который сокращает количество каналов изображения в ratio раз\n",
        "        self.fc1 = nn.Conv2d(in_planes, in_planes // ratio, 1, bias=False)  \n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        # Conv2d слой с ядром 1x1, который восстанавливает количество каналов до исходного значения\n",
        "        self.fc2 = nn.Conv2d(in_planes // ratio, in_planes, 1, bias=False)  \n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Применение адаптивного слоя среднего значения для вычисления среднего по каждому каналу\n",
        "        avg_pool = self.avg_pool(x) \n",
        "        # Применение адаптивного слоя максимального значения для вычисления максимального значения по каждому каналу\n",
        "        max_pool = self.max_pool(x) \n",
        "        # Выполнение операций свертки для уменьшения количества каналов тензора и получение маски внимания, \n",
        "        # основанной на данных, полученных с использованием адаптивного пулинга среднего значения\n",
        "        avg_out = self.fc2(self.relu(self.fc1(avg_pool))) \n",
        "        # Выполнение операций свертки для получения маски внимания на основе данных, \n",
        "        # полученных с использованием адаптивного пулинга максимального значения\n",
        "        max_out = self.fc2(self.relu(self.fc1(max_pool))) \n",
        "        # Объединение двух масок внимания вместе с использованием операции поэлементной конкатенации по оси каналов\n",
        "        out = torch.cat([avg_out, max_out], dim=1) \n",
        "        x = self.sigmoid(x)\n",
        "        return x\n",
        "\n",
        "# Определение класса ResNetWithAttention\n",
        "class ResNetWithAttention(nn.Module):\n",
        "    def __init__(self, num_classes=6):\n",
        "        super(ResNetWithAttention, self).__init__()\n",
        "        self.resnet = models.resnet18(pretrained=True) # Загружаем предобученную нейронную сеть ResNet18 из библиотеки PyTorch\n",
        "        \n",
        "        # Добавляем модули канального и пространсвенного внимания к каждому остаточному блоку.\n",
        "        for module in self.resnet.modules():\n",
        "            if isinstance(module, nn.Sequential):\n",
        "                for i in range(len(module)):\n",
        "                    if isinstance(module[i], BasicBlock):\n",
        "                        module[i].ca = ChannelAttention(module[i].conv2.out_channels)\n",
        "                        module[i].sa = SpatialAttention(module[i].conv2.in_channels)\n",
        "                    elif isinstance(module[i], Bottleneck):\n",
        "                        module[i].ca = ChannelAttention(module[i].conv3.out_channels)\n",
        "                        module[i].sa = SpatialAttention(module[i].conv3.in_channels)\n",
        "\n",
        "        # Заменяем последний полносвязный слой, чтобы на выходе получалось 6 классов\n",
        "        num_features = self.resnet.fc.in_features\n",
        "        self.resnet.fc = nn.Sequential(\n",
        "            nn.Dropout(p=0.2),\n",
        "            nn.Linear(num_features, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Тензор x проходит через операции сверточного слоя, батч-нормализации и функции активации. \n",
        "        x = self.resnet.conv1(x)\n",
        "        x = self.resnet.bn1(x)\n",
        "        x = self.resnet.relu(x)\n",
        "        x = self.resnet.maxpool(x) # Полученный тензор проходит через операцию пулинга maxpool\n",
        "\n",
        "        # Тензор проходит через последовательности слоев ResNet \n",
        "        x = self.resnet.layer1(x)\n",
        "        x = self.resnet.layer2(x)\n",
        "        x = self.resnet.layer3(x)\n",
        "        x = self.resnet.layer4(x)\n",
        "\n",
        "        # Тензор проходит через операцию пулинга avgpool\n",
        "        x = self.resnet.avgpool(x)\n",
        "        x = torch.flatten(x, 1) # тензор \"распрямляется\" в вектор, используя функцию flatten\n",
        "\n",
        "        # Полученный вектор проходит через полносвязный слой fc\n",
        "        x = self.resnet.fc(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "model = ResNetWithAttention()\n",
        "            \n",
        "# Перемещение модели на GPU\n",
        "model.to(device)"
      ],
      "metadata": {
        "id": "ubLAD5Yk1KFd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Обучаем модель\n",
        "\"\"\"\n",
        "# Определяем класс EarlyStopping\n",
        "class EarlyStopping:\n",
        "    def __init__(self, patience=10, delta=0, path='checkpoint.pt'):\n",
        "        # Задаем параметры EarlyStopping: число эпох, в течение которых мы ждем улучшения модели; значение delta, \n",
        "        # являющееся изменением в loss-функции, с которым мы считаем ее улучшение; путь для сохранения весов модели; счетчик неулучшений; \n",
        "        # наилучшее значение метрики качества; флажок ранней остановки; наилучшее значение метрики качества во время валидации.\n",
        "        self.patience = patience\n",
        "        self.delta = delta\n",
        "        self.path = path\n",
        "        self.counter = 0\n",
        "        self.best_score = None\n",
        "        self.early_stop = False\n",
        "        self.val_loss_min = np.Inf\n",
        "\n",
        "    def __call__(self, val_loss, model):\n",
        "        score = -val_loss # Подсчет значения оценки качества модели\n",
        "\n",
        "        # Если это первый запуск, устанавливаем score как лучшее значение\n",
        "        if self.best_score is None:\n",
        "            self.best_score = score\n",
        "            self.save_checkpoint(val_loss, model)\n",
        "        # Если модель не продемонстрировала достаточного улучшения, увеличиваем счетчик и проверяем, не истек ли лимит\n",
        "        elif score < self.best_score + self.delta:\n",
        "            self.counter += 1\n",
        "            if self.counter >= self.patience:\n",
        "                self.early_stop = True\n",
        "        # Если новое значение оценки качества модели лучше, сохраняем веса и сбрасываем счетчик\n",
        "        else:\n",
        "            self.best_score = score\n",
        "            self.save_checkpoint(val_loss, model)\n",
        "            self.counter = 0\n",
        "\n",
        "    def save_checkpoint(self, val_loss, model):\n",
        "        # Сохранение текущих весов модели в файл по указанному пути\n",
        "        torch.save(model.state_dict(), self.path)\n",
        "        # Обновление эталонного значения функции потерь на валидации\n",
        "        self.val_loss_min = val_loss\n",
        "\n",
        "early_stopping = EarlyStopping(patience=10)\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss() # Определение функции потерь кросс-энтропия\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay) # Определение оптимизатора Adam \n",
        "# Определение планировщика ReduceLROnPlateau скорости обучения, \n",
        "# который мы будем использовать для изменения скорости обучения\n",
        "# в зависимости от того, как меняется значение функции потерь\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5) \n",
        "\n",
        "# Код для обучения модели\n",
        "train_loss = []\n",
        "train_acc = []\n",
        "val_loss = []\n",
        "val_acc = []\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    # Обучение модели на тренировочном датасете\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for images, labels in train_dataloader:\n",
        "        # Перемещаем тензоры на устройство\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # Прямое прохождение \n",
        "        outputs = model(images)\n",
        "        loss = loss_fn(outputs, labels)\n",
        "\n",
        "        # Добавление регуляризации\n",
        "        for name, param in model.named_parameters():\n",
        "            # Добавление L2-регуляризации только для весов\n",
        "            if 'weight' in name:\n",
        "                l2_regularization = torch.norm(param) # Вычисление L2-нормы весов\n",
        "                loss += weight_decay * l2_regularization # Добавление к функции потерь вычисленное значение регуляризации с весом `weight_decay`\n",
        "\n",
        "        # Обратное прхождение и оптимизация              \n",
        "        optimizer.zero_grad() # Очистка градиентов, сохраненных в оптимизаторе\n",
        "        loss.backward() # Обратное распространение градиента\n",
        "        optimizer.step() # Обновление параметров модели на основе вычисленных градиентов\n",
        "\n",
        "        # Сохраненяем статистику\n",
        "        running_loss += loss.item() * images.size(0)\n",
        "        _, preds = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (preds == labels).sum().item()\n",
        "\n",
        "        # Очищаем память на устройстве\n",
        "        del images, labels, outputs\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "    # Вычисление функции потерь и точности на тренировочном датасете для текущей эпохи\n",
        "    epoch_train_loss = running_loss / len(train_dataloader.dataset)\n",
        "    epoch_train_acc = 100 * correct / total\n",
        "    # Добавляем значения функции потерь и точности в списки\n",
        "    train_loss.append(epoch_train_loss)\n",
        "    train_acc.append(epoch_train_acc)\n",
        "\n",
        "    # Проверка модели на валидационном датасете\n",
        "    model.eval()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for images, labels in val_dataloader:\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            outputs = model(images)\n",
        "            loss = loss_fn(outputs, labels)\n",
        "\n",
        "            # Сохраненяем статистику\n",
        "            running_loss += loss.item() * images.size(0)\n",
        "            _, preds = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (preds == labels).sum().item()\n",
        "\n",
        "            # Очищаем память на устройстве\n",
        "            del images, labels, outputs\n",
        "            torch.cuda.empty_cache()\n",
        "\n",
        "    # Вычисляем функции потерь и точности на валидационном датасете для текущей эпохи\n",
        "    epoch_val_loss = running_loss / len(val_dataloader.dataset)\n",
        "    epoch_val_acc = 100 * correct / total\n",
        "    # Добавляем значения функции потерь и точности в списки\n",
        "    val_loss.append(epoch_val_loss)\n",
        "    val_acc.append(epoch_val_acc)\n",
        "\n",
        "    print('Epoch [{}/{}], Train Loss: {:.4f}, Train Acc: {:.2f}%, Val Loss: {:.4f}, Val Acc: {:.2f}%'.format(epoch+1, num_epochs, epoch_train_loss, \n",
        "                                                                                                             epoch_train_acc, epoch_val_loss, \n",
        "                                                                                                             epoch_val_acc))\n",
        "    \n",
        "    # Сохраняем модель с лучшей точностью\n",
        "    best_acc = 0\n",
        "    if epoch_val_acc > best_acc:\n",
        "        best_acc = epoch_val_acc\n",
        "        torch.save({\n",
        "            'model': model,\n",
        "            'state_dict': model.state_dict()\n",
        "            }, '/content/resnet50_model_with_dropout_2.pth')\n",
        "\n",
        "    # Уменьшаем learning rate, если в течение 5 эпох точность не улучшается\n",
        "    scheduler.step(epoch_val_loss)\n",
        "    \n",
        "    # Останавливаем обучение, если в течение 10 эпох точность не улучшается\n",
        "    if early_stopping.early_stop:\n",
        "        print(\"Early stopping\")\n",
        "        break\n",
        "\n",
        "# Построение графиков\n",
        "fig, ax = plt.subplots(1, 2, figsize=(12, 5))\n",
        "\n",
        "ax[0].plot(train_loss, label='train')\n",
        "ax[0].plot(val_loss, label='validation')\n",
        "ax[0].set_title('Loss')\n",
        "ax[0].legend()\n",
        "\n",
        "ax[1].plot(train_acc, label='train')\n",
        "ax[1].plot(val_acc, label='validation')\n",
        "ax[1].set_title('Accuracy')\n",
        "ax[1].legend()"
      ],
      "metadata": {
        "id": "vB3da031lpm6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Тестируем модель\n",
        "\"\"\"\n",
        "# Загружаем модель\n",
        "checkpoint = torch.load('/content/resnet50.pth')\n",
        "model = checkpoint['model']\n",
        "model.load_state_dict(checkpoint['state_dict'])\n",
        "\n",
        "# Перемещение модели на устройство\n",
        "model = model.to(device)\n",
        "\n",
        "model.eval()\n",
        "y_true = []\n",
        "y_pred = []\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_dataloader:\n",
        "        # Перемещаем тензоры на устройство\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # Получаем прогнозы модели \n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "        # Вычисляем колличество правильных предсказаний\n",
        "        y_true.extend(labels.cpu().numpy())\n",
        "        y_pred.extend(predicted.cpu().numpy())\n",
        "\n",
        "# Вычисление метрик\n",
        "accuracy = torchmetrics.functional.accuracy(torch.tensor(y_pred), torch.tensor(y_true), num_classes=num_classes, task='multiclass')\n",
        "precision = torchmetrics.functional.precision(torch.tensor(y_pred), torch.tensor(y_true), num_classes=num_classes, average='macro', task='multiclass')\n",
        "recall = torchmetrics.functional.recall(torch.tensor(y_pred), torch.tensor(y_true), num_classes=num_classes, average='macro', task='multiclass')\n",
        "f1 = f1_score(y_true, y_pred, average='macro')\n",
        "\n",
        "print('Accuracy: {:.4f}%, Precision: {:.4f}, Recall: {:.4f}, F1 score: {:.4f}'.format(accuracy * 100, precision, recall, f1))\n",
        "\n",
        "# Строим матрицу ошибок\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "print(\"confusion matrix: \\n\", cm)\n"
      ],
      "metadata": {
        "id": "Vc9A3LtDlpnA"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM6mWJ9mGKwD6hXIBtoC2He",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}